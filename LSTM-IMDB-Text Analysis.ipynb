{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to remove the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenlize(content):\n",
    "    content = re.sub('<.*?>','', content)\n",
    "    filters = ['#','$','%','&',',','\\.',':','\\(','\\)']\n",
    "    content = re.sub(\"|\".join(filters),'',content)\n",
    "    content = re.sub('\\'s', ' is', content)\n",
    "    content = re.sub('\\'re', ' are', content)\n",
    "    content = re.sub('\\'m', ' am', content)\n",
    "    tokens = [i.lower() for i in content.split()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to load Dataset and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imdb_dataset(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        self.train_path = '../../dataset/aclImdb_v1/aclImdb/train/'\n",
    "        self.test_path = '../../dataset/aclImdb_v1/aclImdb/test/'\n",
    "        data_path = self.train_path if train else self.test_path\n",
    "        temp_data_path = [data_path+'pos/', data_path+'neg/']\n",
    "        self.total_file_path = []\n",
    "        for path in temp_data_path:\n",
    "            file_name_list = os.listdir(path)\n",
    "            file_path_list = [path + i for i in file_name_list]\n",
    "            self.total_file_path.extend(file_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.total_file_path[index]\n",
    "        label_list = file_path.split('/')[-2]\n",
    "        label = 0 if label_list == 'neg' else 1\n",
    "        tokens = tokenlize(open(file_path, errors='ignore').read())\n",
    "        return tokens, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.total_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    content, label = list(zip(*batch))\n",
    "    content = [ws.transform(i, sentence_len = 128) for i in content]\n",
    "    content = torch.LongTensor(content)\n",
    "    label = torch.LongTensor(label)\n",
    "    return content, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataloader of training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = imdb_dataset()\n",
    "data_loader = DataLoader(imdb_data, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "test_data = imdb_dataset(train=False)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is to build up a dictionary of data and transform words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2sequence():\n",
    "    unknown_tag = 'UK'   #set a dictionary key for unknown words\n",
    "    padding_tag = 'PAD'  #set a dictionary key for padding\n",
    "    uk = 0               #initial unknown word number sequence as 0\n",
    "    pad = 1              #initial padding sequence as 1\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dict = {\n",
    "            self.unknown_tag : self.uk,     #add the unknown key into dictionary\n",
    "            self.padding_tag : self.pad     #add the padding key into dictionary\n",
    "        }\n",
    "        self.count = {}                     #initial a set for count the frequence of words\n",
    "    \n",
    "    def fit(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.count[word] = self.count.get(word,0) + 1    #counting the words requence\n",
    "            \n",
    "    def get_count():\n",
    "        print(self.count)\n",
    "\n",
    "    #build_vocab function is to build up a dictionary of words\n",
    "    #min_word_times, max_word_times are the condition whether delete some less and very frequence words\n",
    "    #max_dic_len is the maximun words we gonna use in the dictionary\n",
    "    def build_vocab(self, min_word_times=None, max_word_times=None, max_dic_len=None):\n",
    "        if min_word_times is not None:\n",
    "            self.count = {word : value for word, value in self.count.items() if value > min_word_times}\n",
    "        if max_word_times is not None:\n",
    "            self.count = {word : value for word, value in self.count.items() if value < max_word_times}\n",
    "        if max_dic_len is not None: #ranking the words by its frequence\n",
    "            temp = sorted(self.count.items(),key = lambda x:x[-1], reverse=True)[:max_word_times]\n",
    "            self.count = temp\n",
    "        for word in self.count:  #complete the dictionary, each words' sequence depend on its frequence\n",
    "            self.dict[word] = len(self.dict)\n",
    "    \n",
    "    #transform function is tor tranform a sequence of words into a sequence of numbers\n",
    "    #I invoked this function and set the sentence_len=128\n",
    "    def transform(self, sentence, sentence_len=None):\n",
    "        if sentence_len is not None:   \n",
    "            if sentence_len > len(sentence):   #If the number of words is less than 128, its would add some padding at the end\n",
    "                sentence = sentence + [self.padding_tag] * (sentence_len - len(sentence))\n",
    "            if sentence_len < len(sentence):   #If the number of words is more than 128, its would delete the words at the end\n",
    "                sentence = sentence[:sentence_len]\n",
    "        return [self.dict.get(word, self.uk) for word in sentence]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self, max_sentence_len, wv_dim, hidden_size):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        self.wv_dim = wv_dim               #wv_dim is a hyperparameter to define the dimonsion each word would embadding\n",
    "        self.hidden_size = hidden_size     #hidden_Size is the hidden parameter size\n",
    "        self.num_layers = 2                #the layer numer of RNN\n",
    "        self.dropout = 0.5                 #dropout is a hyperparameter for RNN layer\n",
    "        self.embadding = nn.Embedding(len(ws), self.wv_dim)   #define a embadding layer by pytorch.nn lib\n",
    "        self.rnn = nn.RNN(input_size=self.wv_dim,             #define a RNN layer\n",
    "                          hidden_size=self.hidden_size,\n",
    "                          num_layers=self.num_layers, \n",
    "                          dropout=self.dropout, \n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "        self.fc = nn.Linear(self.hidden_size*2, 2)            #difine a linear layer,input dimension is hidden size * 2 because I use bidirectional RNN\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embadding(x)\n",
    "        x, h = self.rnn(x)\n",
    "        output1 = h[-1,:,:]\n",
    "        output2 = h[-2,:,:]\n",
    "        output = torch.cat((output1, output2), dim=-1)        #combine two output as linear layer input\n",
    "        x = self.fc(output)\n",
    "        return f.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, max_sentence_len, wv_dim, hidden_size):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.wv_dim = wv_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = 2\n",
    "        self.dropout = 0.5\n",
    "        self.embadding = nn.Embedding(len(ws), self.wv_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.wv_dim, \n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers, \n",
    "                            dropout=self.dropout, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=True)\n",
    "        self.fc = nn.Linear(self.hidden_size*2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embadding(x)\n",
    "        x, (h, c) = self.lstm(x)\n",
    "        output1 = h[-1,:,:]\n",
    "        output2 = h[-2,:,:]\n",
    "        output = torch.cat((output1, output2), dim=-1)\n",
    "        x = self.fc(output)\n",
    "        return f.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial a word2sequence object(It take a long time every time I fit the data, so I save it as a pkl file and load it when I use it.The annotating code is how I initial this object and fit it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19957\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ws = word2sequence()\n",
    "    data_path = '../../dataset/aclImdb_v1/aclImdb/train/'\n",
    "    temp_data_path = [data_path+'pos/', data_path+'neg/']\n",
    "    total_file_path = []\n",
    "    for path in temp_data_path:\n",
    "        file_name_list = os.listdir(path)\n",
    "        file_path_list = [path + i for i in file_name_list]\n",
    "        for file_path in file_path_list:\n",
    "            sentence = tokenlize(open(file_path,errors='ignore').read())\n",
    "            ws.fit(sentence)\n",
    "    ws.build_vocab(min_word_times=10, max_word_times=10000)\n",
    "    pickle.dump(ws, open('ws.pkl','wb'))\n",
    "    print(len(ws))\n",
    "#     ws = pickle.load(open('../../Pytorch TEST/ws.pkl', 'rb'))\n",
    "#     hidden_size_list = [20,50,100,200,500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a train function to training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model):       #this function need to pass the model\n",
    "    training_loss = []\n",
    "    accuracy = []\n",
    "    model = model\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.001)     #initial the optimizer  \n",
    "    for i in range(epoch):\n",
    "        for idx,(features, labels) in enumerate(data_loader):   #load the data\n",
    "            optimizer.zero_grad()    \n",
    "            label_pre = model(features)                         #prediction the data\n",
    "            loss = f.nll_loss(label_pre, labels)                #get the loss\n",
    "            loss.backward()                                     #backward propagation\n",
    "            optimizer.step()                                    #update parameters\n",
    "            if idx % 50 == 0:                                   #every 50 step, print the training loss\n",
    "                training_loss.append(loss.item())\n",
    "                print('Epoch:%2d    Step:%3d    Loss:%.5f' % (i+1, idx+1, loss.item()))\n",
    "        accuracy.append(test(model))                            #every epoch run a test function and record the accuracy\n",
    "    return training_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a test function to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    model = model\n",
    "    for idx, (features, labels) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            y_pre = model(features)\n",
    "            loss = f.nll_loss(y_pre, labels)\n",
    "            loss_list.append(loss.item())\n",
    "            pred = y_pre.max(dim=-1)[-1]\n",
    "            acc = pred.eq(labels).float().mean()\n",
    "            acc_list.append(acc.item())\n",
    "    print('Average_loss:%.5f   Accuracy:%.5f'%(np.mean(loss_list), np.mean(acc_list))) \n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1    Step:  1    Loss:0.72763\n",
      "Epoch: 1    Step: 51    Loss:0.70999\n",
      "Epoch: 1    Step:101    Loss:0.69719\n",
      "Epoch: 1    Step:151    Loss:0.69308\n",
      "Average_loss:0.69226   Accuracy:0.52714\n",
      "Epoch: 2    Step:  1    Loss:0.69554\n",
      "Epoch: 2    Step: 51    Loss:0.69771\n",
      "Epoch: 2    Step:101    Loss:0.68866\n",
      "Epoch: 2    Step:151    Loss:0.71870\n",
      "Average_loss:0.68487   Accuracy:0.55658\n",
      "Epoch: 3    Step:  1    Loss:0.66870\n",
      "Epoch: 3    Step: 51    Loss:0.69839\n",
      "Epoch: 3    Step:101    Loss:0.66749\n",
      "Epoch: 3    Step:151    Loss:0.66684\n",
      "Average_loss:0.65001   Accuracy:0.62376\n",
      "Epoch: 4    Step:  1    Loss:0.60061\n",
      "Epoch: 4    Step: 51    Loss:0.58995\n",
      "Epoch: 4    Step:101    Loss:0.61256\n",
      "Epoch: 4    Step:151    Loss:0.62906\n",
      "Average_loss:0.62650   Accuracy:0.65386\n",
      "Epoch: 5    Step:  1    Loss:0.62077\n",
      "Epoch: 5    Step: 51    Loss:0.56112\n",
      "Epoch: 5    Step:101    Loss:0.55891\n",
      "Epoch: 5    Step:151    Loss:0.60401\n",
      "Average_loss:0.59340   Accuracy:0.68927\n",
      "Epoch: 6    Step:  1    Loss:0.52740\n",
      "Epoch: 6    Step: 51    Loss:0.62806\n",
      "Epoch: 6    Step:101    Loss:0.51568\n",
      "Epoch: 6    Step:151    Loss:0.57082\n",
      "Average_loss:0.59174   Accuracy:0.69869\n",
      "Epoch: 7    Step:  1    Loss:0.52461\n",
      "Epoch: 7    Step: 51    Loss:0.50409\n",
      "Epoch: 7    Step:101    Loss:0.54503\n",
      "Epoch: 7    Step:151    Loss:0.47801\n",
      "Average_loss:0.59247   Accuracy:0.69019\n",
      "Epoch: 8    Step:  1    Loss:0.49921\n",
      "Epoch: 8    Step: 51    Loss:0.47391\n",
      "Epoch: 8    Step:101    Loss:0.48223\n",
      "Epoch: 8    Step:151    Loss:0.51600\n",
      "Average_loss:0.63902   Accuracy:0.63242\n",
      "Epoch: 9    Step:  1    Loss:0.61478\n",
      "Epoch: 9    Step: 51    Loss:0.55894\n",
      "Epoch: 9    Step:101    Loss:0.51439\n",
      "Epoch: 9    Step:151    Loss:0.53947\n",
      "Average_loss:0.57413   Accuracy:0.70677\n",
      "Epoch:10    Step:  1    Loss:0.41461\n",
      "Epoch:10    Step: 51    Loss:0.46386\n",
      "Epoch:10    Step:101    Loss:0.49540\n",
      "Epoch:10    Step:151    Loss:0.43407\n",
      "Average_loss:0.55799   Accuracy:0.72585\n",
      "Epoch: 1    Step:  1    Loss:0.73044\n",
      "Epoch: 1    Step: 51    Loss:0.68630\n",
      "Epoch: 1    Step:101    Loss:0.68752\n",
      "Epoch: 1    Step:151    Loss:0.68243\n",
      "Average_loss:0.68417   Accuracy:0.56759\n",
      "Epoch: 2    Step:  1    Loss:0.68650\n",
      "Epoch: 2    Step: 51    Loss:0.65002\n",
      "Epoch: 2    Step:101    Loss:0.71193\n",
      "Epoch: 2    Step:151    Loss:0.69409\n",
      "Average_loss:0.68712   Accuracy:0.54893\n",
      "Epoch: 3    Step:  1    Loss:0.67205\n",
      "Epoch: 3    Step: 51    Loss:0.69940\n",
      "Epoch: 3    Step:101    Loss:0.68260\n",
      "Epoch: 3    Step:151    Loss:0.66604\n",
      "Average_loss:0.66224   Accuracy:0.60221\n",
      "Epoch: 4    Step:  1    Loss:0.66549\n",
      "Epoch: 4    Step: 51    Loss:0.58664\n",
      "Epoch: 4    Step:101    Loss:0.64571\n",
      "Epoch: 4    Step:151    Loss:0.61510\n",
      "Average_loss:0.65091   Accuracy:0.62359\n",
      "Epoch: 5    Step:  1    Loss:0.61208\n",
      "Epoch: 5    Step: 51    Loss:0.62233\n",
      "Epoch: 5    Step:101    Loss:0.57857\n",
      "Epoch: 5    Step:151    Loss:0.59744\n",
      "Average_loss:0.64082   Accuracy:0.64059\n",
      "Epoch: 6    Step:  1    Loss:0.52576\n",
      "Epoch: 6    Step: 51    Loss:0.62023\n",
      "Epoch: 6    Step:101    Loss:0.61597\n",
      "Epoch: 6    Step:151    Loss:0.63733\n",
      "Average_loss:0.70445   Accuracy:0.51263\n",
      "Epoch: 7    Step:  1    Loss:0.66882\n",
      "Epoch: 7    Step: 51    Loss:0.59108\n",
      "Epoch: 7    Step:101    Loss:0.59957\n",
      "Epoch: 7    Step:151    Loss:0.61061\n",
      "Average_loss:0.61893   Accuracy:0.66424\n",
      "Epoch: 8    Step:  1    Loss:0.61067\n",
      "Epoch: 8    Step: 51    Loss:0.57090\n",
      "Epoch: 8    Step:101    Loss:0.59744\n",
      "Epoch: 8    Step:151    Loss:0.54723\n",
      "Average_loss:0.65096   Accuracy:0.62402\n",
      "Epoch: 9    Step:  1    Loss:0.59237\n",
      "Epoch: 9    Step: 51    Loss:0.58699\n",
      "Epoch: 9    Step:101    Loss:0.56332\n",
      "Epoch: 9    Step:151    Loss:0.49265\n",
      "Average_loss:0.63095   Accuracy:0.65768\n",
      "Epoch:10    Step:  1    Loss:0.52217\n",
      "Epoch:10    Step: 51    Loss:0.53660\n",
      "Epoch:10    Step:101    Loss:0.51502\n",
      "Epoch:10    Step:151    Loss:0.47308\n",
      "Average_loss:0.63584   Accuracy:0.67336\n",
      "Epoch: 1    Step:  1    Loss:0.74270\n",
      "Epoch: 1    Step: 51    Loss:0.68801\n",
      "Epoch: 1    Step:101    Loss:0.68580\n",
      "Epoch: 1    Step:151    Loss:0.67888\n",
      "Average_loss:0.66868   Accuracy:0.59543\n",
      "Epoch: 2    Step:  1    Loss:0.65893\n",
      "Epoch: 2    Step: 51    Loss:0.65619\n",
      "Epoch: 2    Step:101    Loss:0.69687\n",
      "Epoch: 2    Step:151    Loss:0.68712\n",
      "Average_loss:0.67289   Accuracy:0.58953\n",
      "Epoch: 3    Step:  1    Loss:0.66316\n",
      "Epoch: 3    Step: 51    Loss:0.66908\n",
      "Epoch: 3    Step:101    Loss:0.61614\n",
      "Epoch: 3    Step:151    Loss:0.68289\n",
      "Average_loss:0.69048   Accuracy:0.52989\n",
      "Epoch: 4    Step:  1    Loss:0.69727\n",
      "Epoch: 4    Step: 51    Loss:0.68232\n",
      "Epoch: 4    Step:101    Loss:0.68647\n",
      "Epoch: 4    Step:151    Loss:0.66005\n",
      "Average_loss:0.68675   Accuracy:0.54499\n",
      "Epoch: 5    Step:  1    Loss:0.65998\n",
      "Epoch: 5    Step: 51    Loss:0.65722\n",
      "Epoch: 5    Step:101    Loss:0.66292\n",
      "Epoch: 5    Step:151    Loss:0.63471\n",
      "Average_loss:0.65489   Accuracy:0.61849\n",
      "Epoch: 6    Step:  1    Loss:0.59888\n",
      "Epoch: 6    Step: 51    Loss:0.60433\n",
      "Epoch: 6    Step:101    Loss:0.63862\n",
      "Epoch: 6    Step:151    Loss:0.64162\n",
      "Average_loss:0.67191   Accuracy:0.59032\n",
      "Epoch: 7    Step:  1    Loss:0.65225\n",
      "Epoch: 7    Step: 51    Loss:0.61964\n",
      "Epoch: 7    Step:101    Loss:0.60027\n",
      "Epoch: 7    Step:151    Loss:0.64640\n",
      "Average_loss:0.67503   Accuracy:0.59353\n",
      "Epoch: 8    Step:  1    Loss:0.62710\n",
      "Epoch: 8    Step: 51    Loss:0.58706\n",
      "Epoch: 8    Step:101    Loss:0.59963\n",
      "Epoch: 8    Step:151    Loss:0.74872\n",
      "Average_loss:0.68790   Accuracy:0.54247\n",
      "Epoch: 9    Step:  1    Loss:0.68689\n",
      "Epoch: 9    Step: 51    Loss:0.66241\n",
      "Epoch: 9    Step:101    Loss:0.66130\n",
      "Epoch: 9    Step:151    Loss:0.66800\n",
      "Average_loss:0.68308   Accuracy:0.57051\n",
      "Epoch:10    Step:  1    Loss:0.66780\n",
      "Epoch:10    Step: 51    Loss:0.59522\n",
      "Epoch:10    Step:101    Loss:0.57781\n",
      "Epoch:10    Step:151    Loss:0.59877\n",
      "Average_loss:0.68006   Accuracy:0.63108\n",
      "Epoch: 1    Step:  1    Loss:0.72805\n",
      "Epoch: 1    Step: 51    Loss:0.66916\n",
      "Epoch: 1    Step:101    Loss:0.68932\n",
      "Epoch: 1    Step:151    Loss:0.69095\n",
      "Average_loss:0.68588   Accuracy:0.54055\n",
      "Epoch: 2    Step:  1    Loss:0.68330\n",
      "Epoch: 2    Step: 51    Loss:0.64463\n",
      "Epoch: 2    Step:101    Loss:0.69857\n",
      "Epoch: 2    Step:151    Loss:0.69442\n",
      "Average_loss:0.69328   Accuracy:0.54455\n",
      "Epoch: 3    Step:  1    Loss:0.66247\n",
      "Epoch: 3    Step: 51    Loss:0.66269\n",
      "Epoch: 3    Step:101    Loss:0.66385\n",
      "Epoch: 3    Step:151    Loss:0.69976\n",
      "Average_loss:0.69335   Accuracy:0.53457\n",
      "Epoch: 4    Step:  1    Loss:0.71719\n",
      "Epoch: 4    Step: 51    Loss:0.70819\n",
      "Epoch: 4    Step:101    Loss:0.64412\n",
      "Epoch: 4    Step:151    Loss:0.66256\n",
      "Average_loss:0.69896   Accuracy:0.56861\n",
      "Epoch: 5    Step:  1    Loss:0.70211\n",
      "Epoch: 5    Step: 51    Loss:0.65580\n",
      "Epoch: 5    Step:101    Loss:0.67311\n",
      "Epoch: 5    Step:151    Loss:0.65971\n",
      "Average_loss:0.67473   Accuracy:0.60650\n",
      "Epoch: 6    Step:  1    Loss:0.67443\n",
      "Epoch: 6    Step: 51    Loss:0.70928\n",
      "Epoch: 6    Step:101    Loss:0.68821\n",
      "Epoch: 6    Step:151    Loss:0.67353\n",
      "Average_loss:0.70708   Accuracy:0.51237\n",
      "Epoch: 7    Step:  1    Loss:0.69850\n",
      "Epoch: 7    Step: 51    Loss:0.70486\n",
      "Epoch: 7    Step:101    Loss:0.68528\n",
      "Epoch: 7    Step:151    Loss:0.64387\n",
      "Average_loss:0.69638   Accuracy:0.54335\n",
      "Epoch: 8    Step:  1    Loss:0.67100\n",
      "Epoch: 8    Step: 51    Loss:0.69025\n",
      "Epoch: 8    Step:101    Loss:0.68760\n",
      "Epoch: 8    Step:151    Loss:0.64487\n",
      "Average_loss:0.68440   Accuracy:0.57325\n",
      "Epoch: 9    Step:  1    Loss:0.63594\n",
      "Epoch: 9    Step: 51    Loss:0.62235\n",
      "Epoch: 9    Step:101    Loss:0.61353\n",
      "Epoch: 9    Step:151    Loss:0.63127\n",
      "Average_loss:0.68118   Accuracy:0.58964\n",
      "Epoch:10    Step:  1    Loss:0.59562\n",
      "Epoch:10    Step: 51    Loss:0.56081\n",
      "Epoch:10    Step:101    Loss:0.53676\n",
      "Epoch:10    Step:151    Loss:0.56215\n",
      "Average_loss:0.66545   Accuracy:0.61645\n",
      "Epoch: 1    Step:  1    Loss:0.71922\n",
      "Epoch: 1    Step: 51    Loss:0.70712\n",
      "Epoch: 1    Step:101    Loss:0.67874\n",
      "Epoch: 1    Step:151    Loss:0.67619\n",
      "Average_loss:0.73093   Accuracy:0.50178\n",
      "Epoch: 2    Step:  1    Loss:0.69272\n",
      "Epoch: 2    Step: 51    Loss:0.70453\n",
      "Epoch: 2    Step:101    Loss:0.72898\n",
      "Epoch: 2    Step:151    Loss:0.69914\n",
      "Average_loss:0.69521   Accuracy:0.52526\n",
      "Epoch: 3    Step:  1    Loss:0.68960\n",
      "Epoch: 3    Step: 51    Loss:0.67945\n",
      "Epoch: 3    Step:101    Loss:0.71930\n",
      "Epoch: 3    Step:151    Loss:0.69725\n",
      "Average_loss:0.73791   Accuracy:0.50651\n",
      "Epoch: 4    Step:  1    Loss:0.71657\n",
      "Epoch: 4    Step: 51    Loss:0.69891\n",
      "Epoch: 4    Step:101    Loss:0.70530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4    Step:151    Loss:0.71366\n",
      "Average_loss:0.73748   Accuracy:0.49890\n",
      "Epoch: 5    Step:  1    Loss:0.69907\n",
      "Epoch: 5    Step: 51    Loss:0.68664\n",
      "Epoch: 5    Step:101    Loss:0.68376\n",
      "Epoch: 5    Step:151    Loss:0.66413\n",
      "Average_loss:0.69426   Accuracy:0.54134\n",
      "Epoch: 6    Step:  1    Loss:0.69483\n",
      "Epoch: 6    Step: 51    Loss:0.67158\n",
      "Epoch: 6    Step:101    Loss:0.65860\n",
      "Epoch: 6    Step:151    Loss:0.77928\n",
      "Average_loss:0.71696   Accuracy:0.52782\n",
      "Epoch: 7    Step:  1    Loss:0.67236\n",
      "Epoch: 7    Step: 51    Loss:0.66996\n",
      "Epoch: 7    Step:101    Loss:0.73036\n",
      "Epoch: 7    Step:151    Loss:0.67668\n",
      "Average_loss:0.70153   Accuracy:0.54045\n",
      "Epoch: 8    Step:  1    Loss:0.67262\n",
      "Epoch: 8    Step: 51    Loss:0.69555\n",
      "Epoch: 8    Step:101    Loss:0.76229\n",
      "Epoch: 8    Step:151    Loss:0.66108\n",
      "Average_loss:0.70242   Accuracy:0.54379\n",
      "Epoch: 9    Step:  1    Loss:0.66471\n",
      "Epoch: 9    Step: 51    Loss:0.60784\n",
      "Epoch: 9    Step:101    Loss:0.70460\n",
      "Epoch: 9    Step:151    Loss:0.69242\n",
      "Average_loss:0.72086   Accuracy:0.54248\n",
      "Epoch:10    Step:  1    Loss:0.65341\n",
      "Epoch:10    Step: 51    Loss:0.52694\n",
      "Epoch:10    Step:101    Loss:0.64906\n",
      "Epoch:10    Step:151    Loss:0.67446\n",
      "Average_loss:0.71711   Accuracy:0.54043\n"
     ]
    }
   ],
   "source": [
    "for hidden_size in hidden_size_list:                                                #train the RNN Model with different hidden size\n",
    "    rnn_model = RNN_Model(max_sentence_len=128, wv_dim=64, hidden_size=hidden_size) #initial the RNN model\n",
    "    training_loss, accuracy = train(10, rnn_model)                                  #training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1    Step:  1    Loss:0.68859\n",
      "Epoch: 1    Step: 51    Loss:0.69103\n",
      "Epoch: 1    Step:101    Loss:0.68680\n",
      "Epoch: 1    Step:151    Loss:0.67059\n",
      "Average_loss:0.69324   Accuracy:0.59749\n",
      "Epoch: 2    Step:  1    Loss:0.69469\n",
      "Epoch: 2    Step: 51    Loss:0.64526\n",
      "Epoch: 2    Step:101    Loss:0.64956\n",
      "Epoch: 2    Step:151    Loss:0.51612\n",
      "Average_loss:0.56728   Accuracy:0.71349\n",
      "Epoch: 3    Step:  1    Loss:0.56267\n",
      "Epoch: 3    Step: 51    Loss:0.56462\n",
      "Epoch: 3    Step:101    Loss:0.47008\n",
      "Epoch: 3    Step:151    Loss:0.49458\n",
      "Average_loss:0.51612   Accuracy:0.74405\n",
      "Epoch: 4    Step:  1    Loss:0.46314\n",
      "Epoch: 4    Step: 51    Loss:0.44098\n",
      "Epoch: 4    Step:101    Loss:0.42901\n",
      "Epoch: 4    Step:151    Loss:0.39966\n",
      "Average_loss:0.47173   Accuracy:0.78273\n",
      "Epoch: 5    Step:  1    Loss:0.38456\n",
      "Epoch: 5    Step: 51    Loss:0.39024\n",
      "Epoch: 5    Step:101    Loss:0.34309\n",
      "Epoch: 5    Step:151    Loss:0.31015\n",
      "Average_loss:0.44700   Accuracy:0.79963\n",
      "Epoch: 6    Step:  1    Loss:0.28338\n",
      "Epoch: 6    Step: 51    Loss:0.29011\n",
      "Epoch: 6    Step:101    Loss:0.33087\n",
      "Epoch: 6    Step:151    Loss:0.28876\n",
      "Average_loss:0.44947   Accuracy:0.79121\n",
      "Epoch: 7    Step:  1    Loss:0.32176\n",
      "Epoch: 7    Step: 51    Loss:0.29257\n",
      "Epoch: 7    Step:101    Loss:0.36935\n",
      "Epoch: 7    Step:151    Loss:0.31984\n",
      "Average_loss:0.44594   Accuracy:0.80907\n",
      "Epoch: 8    Step:  1    Loss:0.31965\n",
      "Epoch: 8    Step: 51    Loss:0.32206\n",
      "Epoch: 8    Step:101    Loss:0.27998\n",
      "Epoch: 8    Step:151    Loss:0.35918\n",
      "Average_loss:0.44487   Accuracy:0.81059\n",
      "Epoch: 9    Step:  1    Loss:0.17263\n",
      "Epoch: 9    Step: 51    Loss:0.21910\n",
      "Epoch: 9    Step:101    Loss:0.19181\n",
      "Epoch: 9    Step:151    Loss:0.21015\n",
      "Average_loss:0.44969   Accuracy:0.80778\n",
      "Epoch:10    Step:  1    Loss:0.19011\n",
      "Epoch:10    Step: 51    Loss:0.23563\n",
      "Epoch:10    Step:101    Loss:0.19395\n",
      "Epoch:10    Step:151    Loss:0.20252\n",
      "Average_loss:0.47042   Accuracy:0.80466\n",
      "Epoch: 1    Step:  1    Loss:0.69586\n",
      "Epoch: 1    Step: 51    Loss:0.70051\n",
      "Epoch: 1    Step:101    Loss:0.67214\n",
      "Epoch: 1    Step:151    Loss:0.65452\n",
      "Average_loss:0.60938   Accuracy:0.66971\n",
      "Epoch: 2    Step:  1    Loss:0.57437\n",
      "Epoch: 2    Step: 51    Loss:0.51179\n",
      "Epoch: 2    Step:101    Loss:0.56616\n",
      "Epoch: 2    Step:151    Loss:0.47273\n",
      "Average_loss:0.53284   Accuracy:0.73878\n",
      "Epoch: 3    Step:  1    Loss:0.42828\n",
      "Epoch: 3    Step: 51    Loss:0.43037\n",
      "Epoch: 3    Step:101    Loss:0.44455\n",
      "Epoch: 3    Step:151    Loss:0.68527\n",
      "Average_loss:0.67487   Accuracy:0.58046\n",
      "Epoch: 4    Step:  1    Loss:0.68801\n",
      "Epoch: 4    Step: 51    Loss:0.63813\n",
      "Epoch: 4    Step:101    Loss:0.55943\n",
      "Epoch: 4    Step:151    Loss:0.55270\n",
      "Average_loss:0.54953   Accuracy:0.73107\n",
      "Epoch: 5    Step:  1    Loss:0.50397\n",
      "Epoch: 5    Step: 51    Loss:0.62780\n",
      "Epoch: 5    Step:101    Loss:0.59078\n",
      "Epoch: 5    Step:151    Loss:0.50423\n",
      "Average_loss:0.53650   Accuracy:0.74405\n",
      "Epoch: 6    Step:  1    Loss:0.51274\n",
      "Epoch: 6    Step: 51    Loss:0.40662\n",
      "Epoch: 6    Step:101    Loss:0.46649\n",
      "Epoch: 6    Step:151    Loss:0.40585\n",
      "Average_loss:0.47785   Accuracy:0.77721\n",
      "Epoch: 7    Step:  1    Loss:0.37613\n",
      "Epoch: 7    Step: 51    Loss:0.38209\n",
      "Epoch: 7    Step:101    Loss:0.40106\n",
      "Epoch: 7    Step:151    Loss:0.36917\n",
      "Average_loss:0.45435   Accuracy:0.79111\n",
      "Epoch: 8    Step:  1    Loss:0.35098\n",
      "Epoch: 8    Step: 51    Loss:0.35119\n",
      "Epoch: 8    Step:101    Loss:0.37056\n",
      "Epoch: 8    Step:151    Loss:0.30591\n",
      "Average_loss:0.43889   Accuracy:0.79710\n",
      "Epoch: 9    Step:  1    Loss:0.34495\n",
      "Epoch: 9    Step: 51    Loss:0.32910\n",
      "Epoch: 9    Step:101    Loss:0.31122\n",
      "Epoch: 9    Step:151    Loss:0.22370\n",
      "Average_loss:0.41630   Accuracy:0.81518\n",
      "Epoch:10    Step:  1    Loss:0.31219\n",
      "Epoch:10    Step: 51    Loss:0.28630\n",
      "Epoch:10    Step:101    Loss:0.26664\n",
      "Epoch:10    Step:151    Loss:0.35668\n",
      "Average_loss:0.42879   Accuracy:0.81401\n",
      "Epoch: 1    Step:  1    Loss:0.69638\n",
      "Epoch: 1    Step: 51    Loss:0.67052\n",
      "Epoch: 1    Step:101    Loss:0.62697\n",
      "Epoch: 1    Step:151    Loss:0.63293\n",
      "Average_loss:0.59717   Accuracy:0.70663\n",
      "Epoch: 2    Step:  1    Loss:0.49628\n",
      "Epoch: 2    Step: 51    Loss:0.50548\n",
      "Epoch: 2    Step:101    Loss:0.47816\n",
      "Epoch: 2    Step:151    Loss:0.48279\n",
      "Average_loss:0.52834   Accuracy:0.74122\n",
      "Epoch: 3    Step:  1    Loss:0.42352\n",
      "Epoch: 3    Step: 51    Loss:0.43751\n",
      "Epoch: 3    Step:101    Loss:0.59548\n",
      "Epoch: 3    Step:151    Loss:0.58160\n",
      "Average_loss:0.50268   Accuracy:0.76058\n",
      "Epoch: 4    Step:  1    Loss:0.52003\n",
      "Epoch: 4    Step: 51    Loss:0.38240\n",
      "Epoch: 4    Step:101    Loss:0.51017\n",
      "Epoch: 4    Step:151    Loss:0.56619\n",
      "Average_loss:0.46141   Accuracy:0.78413\n",
      "Epoch: 5    Step:  1    Loss:0.38886\n",
      "Epoch: 5    Step: 51    Loss:0.31781\n",
      "Epoch: 5    Step:101    Loss:0.32485\n",
      "Epoch: 5    Step:151    Loss:0.42467\n",
      "Average_loss:0.43887   Accuracy:0.80010\n",
      "Epoch: 6    Step:  1    Loss:0.38050\n",
      "Epoch: 6    Step: 51    Loss:0.35965\n",
      "Epoch: 6    Step:101    Loss:0.31084\n",
      "Epoch: 6    Step:151    Loss:0.32377\n",
      "Average_loss:0.49687   Accuracy:0.80536\n",
      "Epoch: 7    Step:  1    Loss:0.41382\n",
      "Epoch: 7    Step: 51    Loss:0.62771\n",
      "Epoch: 7    Step:101    Loss:0.58144\n",
      "Epoch: 7    Step:151    Loss:0.54567\n",
      "Average_loss:0.52727   Accuracy:0.74019\n",
      "Epoch: 8    Step:  1    Loss:0.40256\n",
      "Epoch: 8    Step: 51    Loss:0.36561\n",
      "Epoch: 8    Step:101    Loss:0.46026\n",
      "Epoch: 8    Step:151    Loss:0.39923\n",
      "Average_loss:0.43589   Accuracy:0.79896\n",
      "Epoch: 9    Step:  1    Loss:0.35826\n",
      "Epoch: 9    Step: 51    Loss:0.26877\n",
      "Epoch: 9    Step:101    Loss:0.20572\n",
      "Epoch: 9    Step:151    Loss:0.28498\n",
      "Average_loss:0.42484   Accuracy:0.81522\n",
      "Epoch:10    Step:  1    Loss:0.39859\n",
      "Epoch:10    Step: 51    Loss:0.31251\n",
      "Epoch:10    Step:101    Loss:0.29880\n",
      "Epoch:10    Step:151    Loss:0.28387\n",
      "Average_loss:0.41525   Accuracy:0.81672\n",
      "Epoch: 1    Step:  1    Loss:0.69126\n",
      "Epoch: 1    Step: 51    Loss:0.65288\n",
      "Epoch: 1    Step:101    Loss:0.62118\n",
      "Epoch: 1    Step:151    Loss:0.58009\n",
      "Average_loss:0.59185   Accuracy:0.68972\n",
      "Epoch: 2    Step:  1    Loss:0.49573\n",
      "Epoch: 2    Step: 51    Loss:0.59435\n",
      "Epoch: 2    Step:101    Loss:0.61055\n",
      "Epoch: 2    Step:151    Loss:0.52832\n",
      "Average_loss:0.67715   Accuracy:0.63011\n",
      "Epoch: 3    Step:  1    Loss:0.61629\n",
      "Epoch: 3    Step: 51    Loss:0.67684\n",
      "Epoch: 3    Step:101    Loss:0.63522\n",
      "Epoch: 3    Step:151    Loss:0.55240\n",
      "Average_loss:0.56228   Accuracy:0.70760\n",
      "Epoch: 4    Step:  1    Loss:0.52553\n",
      "Epoch: 4    Step: 51    Loss:0.55660\n",
      "Epoch: 4    Step:101    Loss:0.45607\n",
      "Epoch: 4    Step:151    Loss:0.42798\n",
      "Average_loss:0.49131   Accuracy:0.75854\n",
      "Epoch: 5    Step:  1    Loss:0.45323\n",
      "Epoch: 5    Step: 51    Loss:0.43855\n",
      "Epoch: 5    Step:101    Loss:0.55211\n",
      "Epoch: 5    Step:151    Loss:0.37008\n",
      "Average_loss:0.43758   Accuracy:0.80126\n",
      "Epoch: 6    Step:  1    Loss:0.34964\n",
      "Epoch: 6    Step: 51    Loss:0.29591\n",
      "Epoch: 6    Step:101    Loss:0.39526\n",
      "Epoch: 6    Step:151    Loss:0.32238\n",
      "Average_loss:0.43991   Accuracy:0.81544\n",
      "Epoch: 7    Step:  1    Loss:0.31983\n",
      "Epoch: 7    Step: 51    Loss:0.36513\n",
      "Epoch: 7    Step:101    Loss:0.32030\n",
      "Epoch: 7    Step:151    Loss:0.27482\n",
      "Average_loss:0.43600   Accuracy:0.81064\n",
      "Epoch: 8    Step:  1    Loss:0.28403\n",
      "Epoch: 8    Step: 51    Loss:0.21858\n",
      "Epoch: 8    Step:101    Loss:0.27414\n",
      "Epoch: 8    Step:151    Loss:0.37627\n",
      "Average_loss:0.41833   Accuracy:0.81851\n",
      "Epoch: 9    Step:  1    Loss:0.29653\n",
      "Epoch: 9    Step: 51    Loss:0.33980\n",
      "Epoch: 9    Step:101    Loss:0.27287\n",
      "Epoch: 9    Step:151    Loss:0.27876\n",
      "Average_loss:0.42552   Accuracy:0.82583\n",
      "Epoch:10    Step:  1    Loss:0.27073\n",
      "Epoch:10    Step: 51    Loss:0.28357\n",
      "Epoch:10    Step:101    Loss:0.29733\n",
      "Epoch:10    Step:151    Loss:0.16841\n",
      "Average_loss:0.43893   Accuracy:0.82337\n",
      "Epoch: 1    Step:  1    Loss:0.69289\n",
      "Epoch: 1    Step: 51    Loss:0.67341\n",
      "Epoch: 1    Step:101    Loss:0.69930\n",
      "Epoch: 1    Step:151    Loss:0.62032\n",
      "Average_loss:0.66301   Accuracy:0.60537\n",
      "Epoch: 2    Step:  1    Loss:0.63777\n",
      "Epoch: 2    Step: 51    Loss:0.65030\n",
      "Epoch: 2    Step:101    Loss:0.61466\n",
      "Epoch: 2    Step:151    Loss:0.58940\n",
      "Average_loss:0.63789   Accuracy:0.63051\n",
      "Epoch: 3    Step:  1    Loss:0.61529\n",
      "Epoch: 3    Step: 51    Loss:0.64460\n",
      "Epoch: 3    Step:101    Loss:0.58387\n",
      "Epoch: 3    Step:151    Loss:0.64583\n",
      "Average_loss:0.56249   Accuracy:0.71781\n",
      "Epoch: 4    Step:  1    Loss:0.45957\n",
      "Epoch: 4    Step: 51    Loss:0.49343\n",
      "Epoch: 4    Step:101    Loss:0.43421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4    Step:151    Loss:0.53905\n",
      "Average_loss:0.48081   Accuracy:0.77963\n",
      "Epoch: 5    Step:  1    Loss:0.45143\n",
      "Epoch: 5    Step: 51    Loss:0.38667\n",
      "Epoch: 5    Step:101    Loss:0.43056\n",
      "Epoch: 5    Step:151    Loss:0.45227\n",
      "Average_loss:0.45828   Accuracy:0.77951\n",
      "Epoch: 6    Step:  1    Loss:0.36694\n",
      "Epoch: 6    Step: 51    Loss:0.29234\n",
      "Epoch: 6    Step:101    Loss:0.29500\n",
      "Epoch: 6    Step:151    Loss:0.40045\n",
      "Average_loss:0.41725   Accuracy:0.81314\n",
      "Epoch: 7    Step:  1    Loss:0.35777\n",
      "Epoch: 7    Step: 51    Loss:0.32385\n",
      "Epoch: 7    Step:101    Loss:0.24643\n",
      "Epoch: 7    Step:151    Loss:0.31021\n",
      "Average_loss:0.42391   Accuracy:0.81973\n",
      "Epoch: 8    Step:  1    Loss:0.27387\n",
      "Epoch: 8    Step: 51    Loss:0.31804\n",
      "Epoch: 8    Step:101    Loss:0.25637\n",
      "Epoch: 8    Step:151    Loss:0.26698\n",
      "Average_loss:0.44923   Accuracy:0.81761\n",
      "Epoch: 9    Step:  1    Loss:0.24818\n",
      "Epoch: 9    Step: 51    Loss:0.21091\n",
      "Epoch: 9    Step:101    Loss:0.18121\n",
      "Epoch: 9    Step:151    Loss:0.22933\n",
      "Average_loss:0.46527   Accuracy:0.81889\n",
      "Epoch:10    Step:  1    Loss:0.15189\n",
      "Epoch:10    Step: 51    Loss:0.09033\n",
      "Epoch:10    Step:101    Loss:0.21809\n",
      "Epoch:10    Step:151    Loss:0.18277\n",
      "Average_loss:0.50195   Accuracy:0.82132\n"
     ]
    }
   ],
   "source": [
    "for hidden_size in hidden_size_list:                                                   #train the LSTM model with different hidden size\n",
    "    lstm_model = LSTM_Model(max_sentence_len=128, wv_dim=64, hidden_size=hidden_size)  #intial the LSTM Model\n",
    "    training_loss2, accuracy2 = train(10, lstm_model)                                  #training the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
